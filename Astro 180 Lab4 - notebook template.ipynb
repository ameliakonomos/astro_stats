{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Python / Numerical Python\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "import matplotlib as mpl\n",
    "import pylab\n",
    "import sys; sys.path.append('/home/a180i/lib/python/')\n",
    "import a180\n",
    "import os\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Index arrays\n",
    "\n",
    "Sometimes we want to access only certain elements in a Python array.  We have seen some aspects of indexing before, for example, using the square brackets to access a single element or a range of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n",
      "pig\n",
      "['parrot' 'pig' 'hamster']\n"
     ]
    }
   ],
   "source": [
    "x = np.array(['cat', 'dog', 'parrot', 'pig', 'hamster', 'horse', 'snake', 'tarantula'])\n",
    "print(x[0])\n",
    "print(x[3]) # remember indexing counts from 0\n",
    "print(x[2:5]) # elements 2, 3, and 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, sometimes we want to access non-contiguous sets of elements.  This is where index arrays come in.  An index array is a numpy array of indices.  (For n-dimensional arrays, it is a tuple of 1d numpy arrays; more later.)  We can then use the index array in the square brackets to get the elements in question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog' 'pig' 'horse']\n"
     ]
    }
   ],
   "source": [
    "ix = np.array([1,3,5]) # an index array\n",
    "print(x[ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can even use them for assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat' 'frog' 'parrot' 'frog' 'hamster' 'frog' 'snake' 'tarantula']\n"
     ]
    }
   ],
   "source": [
    "x[ix] = 'frog'\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-d index arrays\n",
    "\n",
    "We can use index arrays for 2d numpy arrays as well.  This structure is a tuple of arrays of 1d indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cat' 'dog' 'parrot' 'pig']\n",
      " ['hamster' 'horse' 'snake' 'tarantula']]\n",
      "['cat' 'parrot' 'pig' 'tarantula']\n"
     ]
    }
   ],
   "source": [
    "x = np.array(['cat', 'dog', 'parrot', 'pig', 'hamster', 'horse', 'snake', 'tarantula'])\n",
    "x.shape = (2,4)\n",
    "print(x)\n",
    "ix = (np.array([0,0,0,1]), np.array([0,2,3,3]))\n",
    "print(x[ix]) # see if you can guess what this will be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using np.nonzero to get index arrays\n",
    "\n",
    "We might be interested in finding certain locations where a condition is met.  For example, everywhere in an array that is above a certain threshold.  We use numpy arrays to do the appropriate comparison, which will give us an array of True/False boolean values.  We then use the nonzero function to get all the locations where the condition is True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.19362831  0.23535604 -1.36463047  0.6840092   0.06913435]\n",
      " [ 2.65691355 -1.59042836 -1.21379803 -0.230818   -1.2192997 ]\n",
      " [ 0.34197711 -0.03586939  0.38956104  0.65291325  0.91048475]\n",
      " [-0.50070145 -1.00648692 -0.49634442 -0.02069466  1.52757602]\n",
      " [ 1.30669699  0.42127146 -0.04066732 -0.61880902  0.3106665 ]]\n",
      "(array([0, 0, 1, 2, 2, 3, 4]), array([0, 3, 0, 3, 4, 4, 0]))\n",
      "[1.19362831 0.6840092  2.65691355 0.65291325 0.91048475 1.52757602\n",
      " 1.30669699]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.randn(5,5) # get a 5x5 array of random values, gaussian distributed with zero mean and sigma=1\n",
    "print(x)\n",
    "w = np.nonzero(x > 0.5) # get indices of all the locations above 0.5\n",
    "print(w) # print the indices\n",
    "print(x[w]) # print the values.  Note that this is a 1d array of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with directories and filenames\n",
    "\n",
    "To combine a directory name and a file name, you can usually do something like \n",
    "\n",
    "``combined_filename = directory + filename``\n",
    "\n",
    "However, what if the directory name does not have a ``/`` at the end? Adding the two variables will give an incorrect file name where the directory name and the file names are joined together. \n",
    "\n",
    "The way to avoid this is to use ``os.path.join``. This function will create a string that combines a directory name with a filename, taking care of the ending ``/`` for you. Try it below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/file1.fits\n",
      "/datafile1.fits\n",
      "/data/file1.fits\n",
      "/data/file1.fits\n"
     ]
    }
   ],
   "source": [
    "directory_name1 = '/data/'\n",
    "directory_name2 = '/data'\n",
    "filename1 = 'file1.fits'\n",
    "\n",
    "# Because one of the directory name is missing a /, the following two lines give different answers\n",
    "print(directory_name1+filename1)\n",
    "print(directory_name2+filename1)\n",
    "\n",
    "# However, if we use os.path.join, you can avoid this bug\n",
    "print(os.path.join(directory_name1,filename1))\n",
    "print(os.path.join(directory_name2,filename1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Color-Magnitude Diagram\n",
    "\n",
    "\n",
    "## Basic Data Reduction\n",
    "\n",
    "One of the first tasks is to reduce all the data frames, namely through the creation of a flat field frames for each filter used, then sky-subtraction and flat-field correction of all target and photometric standard star exposures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "(7945, 7946)\n",
      "(7945, 7946)\n"
     ]
    }
   ],
   "source": [
    "# lists of raw exposures.  Be sure to keep track of which filter they're used for.\n",
    "import numpy \n",
    "data_dir = '/data/home/a180f/lab4_raw/'\n",
    "reduced_dir = '/data/home/a180f/lab4_proc/'\n",
    "\n",
    "im_V = fits.getdata(data_dir+'hst_17077_12_wfc3_uvis_f606w_iexu12_drc.fits')\n",
    "im_R = fits.getdata(data_dir+'hst_17077_12_wfc3_uvis_f814w_iexu12_drc.fits')\n",
    "\n",
    "im_V = numpy.array(im_V)\n",
    "im_R = numpy.array(im_R)\n",
    "\n",
    "#steps done by HST already\n",
    "# dark exposures (used for calibrating flat field exposures)\n",
    "# raw flat field exposures\n",
    "# raw sky exposures\n",
    "# raw photometric standard star exposures\n",
    "# raw target exposures\n",
    "\n",
    "# NOTE:  for the following, save the output into appropriate\n",
    "#\n",
    "\n",
    "# create the flat field frames\n",
    "#\n",
    "\n",
    "# file names for flat field calibration frames\n",
    "\n",
    "# for each flat field calibration frame\n",
    "\n",
    "# load all exposures and combine\n",
    "    \n",
    "# normalize by median of combined array\n",
    "\n",
    "# mark pixels with low or high values as NaN\n",
    "# thresh = (0.05, 2.5) # low and high thresholds for marking bad values\n",
    "# w = np.nonzero((flat < thresh[0]) | (flat > thresh[1]))  # note the | symbol does a logical OR operation\n",
    "# flat[w] = np.nan\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # array of filenames for reduced data\n",
    "# reduced_filenames_V = FIXME\n",
    "\n",
    "# # iterate over all the exposures\n",
    "# for i in arange(len(reduced_filenames_V)):\n",
    "    \n",
    "#     # sky subtract and flat-field correct all standard star and target exposures\n",
    "\n",
    "    \n",
    "#     # then save each file into the reduced directory\n",
    "#     fits.writeto(os.path.join(reduced_dir,reduced_filenames_V[i]),)\n",
    "print('done')\n",
    "print(np.shape(im_V))\n",
    "print(np.shape(im_R))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating mosaic images\n",
    "\n",
    "Our aims are to get photometry on stars in the cluster.  Our data, however, are taken at multiple pointings, so stars may show up in one frame and not another.  They might also appear in multiple frames.  To combine our data effectively, we'll want to assign a unique identifier to each star.  And in order to do that, we can first create a combined mosaic image.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#SKIP THIS BLOCK\n",
    "#create function\n",
    "def create_mosaic(frame_offsets, filenames, show=False):\n",
    "    \"given a list of frame offsets and filenames, combine the images into a common mosaic frame\"\n",
    "\n",
    "    # compute the dimensions of the mosaic image\n",
    "    # FIXME  replace im below with a real loaded image frame\n",
    "    im = fits.getdata(filenames[0])\n",
    "    im_shape = im.shape  # get the dimensions of the individual exposures (Ny, Nx)\n",
    "    mos_shape = im_shape + np.max(frame_offsets_V, axis=0)  # dimensions of mosaic array    \n",
    "    \n",
    "    \n",
    "    # create mosaic\n",
    "    mos = np.zeros(mos_shape, dtype=np.float) + np.nan  # will hold mosaic array; initialize with NaN values\n",
    "    counter = np.zeros(mos_shape, dtype=np.int)  # will hold number of images contributing to pixel; used later in averaging\n",
    "    # accumulate images into mosaic frame\n",
    "    for i, fn in enumerate(filenames):  # loop over calibrated V-band exposures\n",
    "        im = fits.getdata(fn)  # load the image data from FITS       \n",
    "                \n",
    "        # process the image data (if necessary)\n",
    "        pim = im # TEMP\n",
    "        \n",
    "        \n",
    "\n",
    "        tempmos = mos[frame_offsets[i][0]:frame_offsets[i][0] + im_shape[0],\n",
    "                      frame_offsets[i][1]:frame_offsets[i][1] + im_shape[1]]\n",
    "        \n",
    "        addmos = np.nansum(np.dstack((tempmos, pim)), 2)\n",
    "        \n",
    "        mos[frame_offsets[i][0]:frame_offsets[i][0] + im_shape[0],\n",
    "            frame_offsets[i][1]:frame_offsets[i][1] + im_shape[1]] = addmos\n",
    "        \n",
    "        # increase the counter for where this image is placed\n",
    "        counter[frame_offsets[i][0]:frame_offsets[i][0] + im_shape[0],\n",
    "                frame_offsets[i][1]:frame_offsets[i][1] + im_shape[1]] += 1        \n",
    "        \n",
    "        \n",
    "    # now divide by number of images to get the average\n",
    "    w = np.nonzero(counter)\n",
    "    mos[w] /= counter[w]\n",
    "\n",
    "    # display the mosaic\n",
    "    if show:\n",
    "        pass  # replace with plotting code\n",
    "    \n",
    "    # return the mosiac\n",
    "    return mos\n",
    "\n",
    "# Just run this cell to load in the mosaic code\n",
    "\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FIXME' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#SKIP\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# create V-band mosaic\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# This should be a list of (y, x) pairs for the offsets of each of the V-band exposures\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#  NOTE  you will have to determine these\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#  NOTE  it will probably be best if you have a consistent set of offsets among all filters so that the a given star appears in the same location in each mosaic\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m frame_offsets_V \u001b[38;5;241m=\u001b[39m [(\u001b[43mFIXME\u001b[49m, FIXME),\n\u001b[1;32m      8\u001b[0m                    (FIXME, FIXME),\n\u001b[1;32m      9\u001b[0m                    (FIXME, FIXME),\n\u001b[1;32m     10\u001b[0m                   ]\n\u001b[1;32m     11\u001b[0m frame_offsets_V \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(frame_offsets_V)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# create the mosaic\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'FIXME' is not defined"
     ]
    }
   ],
   "source": [
    "#SKIP\n",
    "# create V-band mosaic\n",
    "\n",
    "# This should be a list of (y, x) pairs for the offsets of each of the V-band exposures\n",
    "#  NOTE  you will have to determine these\n",
    "#  NOTE  it will probably be best if you have a consistent set of offsets among all filters so that the a given star appears in the same location in each mosaic\n",
    "frame_offsets_V = [(FIXME, FIXME),\n",
    "                   (FIXME, FIXME),\n",
    "                   (FIXME, FIXME),\n",
    "                  ]\n",
    "frame_offsets_V = np.array(frame_offsets_V)\n",
    "\n",
    "# create the mosaic\n",
    "mos_V = create_mosiac(frame_offsets_V, calib_frames_V, show=True)\n",
    "\n",
    "# save the mosaic to file\n",
    "mosaic_savefile_V = FIXME\n",
    "fits.writeto(os.path.join(reduced_dir,mosaic_savefile_V),mos_V)\n",
    "\n",
    "# Now repeat this for other filters\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SKIP\n",
    "# after the previous steps and the data is saved, do you do not need to reduced the data again \n",
    "# everytime you run your notebook. You can just load in your files here\n",
    "\n",
    "# uncomment and change to load in the saved files instead of recreating the mosaic each time\n",
    "\n",
    "reduced_dir = ('/data/home/a180f/lab4_raw/')\n",
    "mosaic_savefile_V = ('hst_17077_12_wfc3_uvis_f606w_iexu12_drc.fits')\n",
    "mos_V = fits.getdata(os.path.join(reduced_dir,mosaic_savefile_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identifying the stars\n",
    "\n",
    "We'll want a method for identifying stars so that we can assign each a unique identifier.  We only really need to identify stars for which we can get detections in all bands.\n",
    "\n",
    "We can make the identifications in the mosaic frame.  However, when we do photometry, we should try (if possible) to do it in each target exposure, then later combine the photometry.\n",
    "\n",
    "We'll want a robust way of automatically identifying stars.  This could be done by first smoothing the image then identifying the peaks.  However, we have the confounding factor of cosmic ray hits.  (Note that they could be posive or negative, since we subtracted sky exposures.)  So we will first want to identify all the cosmic rays.  Then we can tag them with NaN values just as we did with bad pixels in the calibration steps above.  Finally, we can, for the identification steps, replace the NaN values with a combination of good values from the pixels' neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE doing cosmic ray removal can take a really long time! \n",
    "# It's okay to skip this step if you took more than 1 image at each mosaic position and \n",
    "# you median combined them\n",
    "\n",
    "from scipy.ndimage import median_filter, percentile_filter, gaussian_filter\n",
    "\n",
    "def median_replace(im, medfilt=5):\n",
    "    \"replace NaN values with those determined from a local median filter\"\n",
    "    \n",
    "    mfim = median_filter(im, size=medfilt,\n",
    "                         #mode='constant',\n",
    "                         cval=0.)\n",
    "\n",
    "    # get locations where value is NaN\n",
    "    w = np.isnan(im)\n",
    "    # replace those locations in the image with values from the median-filtered image\n",
    "    pim = im.copy()\n",
    "    pim[w] = mfim[w]\n",
    "    \n",
    "    return pim\n",
    "\n",
    "\n",
    "def identify_cr(im, thresh=10.):\n",
    "    \"\"\"\n",
    "    return an index array of pixels flagged to be possible cosmic-ray hits.  \n",
    "    thresh gives a factor fow how many times above (or below) the local background \n",
    "    sigma a pixel must be to be flagged.\n",
    "    \"\"\"\n",
    "\n",
    "    # do a high-pass filter to take out \"sky\" variations\n",
    "    skyfilt = 50 # [pix]\n",
    "    sfim = im - median_filter(im, size=skyfilt,\n",
    "                              #mode='constant',\n",
    "                              cval=0.)\n",
    "\n",
    "    \n",
    "    \n",
    "    # estimate the local image sigma.  Don't use standard deviation, since that will be biased by CRs.\n",
    "    # Instead, use rank filters\n",
    "    sigfilt = 10 # [pix]\n",
    "    pf1 = percentile_filter(sfim, 50-34.1, size=sigfilt,\n",
    "                            cval=0.)\n",
    "    pf2 = percentile_filter(sfim, 50+34.1, size=sigfilt,\n",
    "                            cval=0.)\n",
    "    sig = (pf2-pf1)/2. # half dist. between locations of 1-sig confidence\n",
    "\n",
    "    \n",
    "    # now patch over NaNs with a median-filtered image\n",
    "    medfilt = 5 # [pix]\n",
    "    tsfim = median_replace(sfim, medfilt=medfilt)\n",
    "    \n",
    "    \n",
    "   \n",
    "    bad = (tsfim > tsfim + thresh*sig) | (tsfim < tsfim - thresh*sig)\n",
    "    \n",
    "####################### Most likely will need to call thresh at a lower value, like 3 ########################\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return np.nonzero(bad)\n",
    "\n",
    "\n",
    "# use the above routines to identify CR values in the mosaics and mark them with NaN\n",
    "\n",
    "# this can be very slow! Only run this if you find your data has too many cosmic rays.\n",
    "mos_V = identify_cr(im_V)\n",
    "\n",
    "# then replace all NaN values with median-filtered values. You can run this step even if you don't run\n",
    "# the cosmic ray removal to get rid of NaNs\n",
    "\n",
    "mos_V = median_replace(im_V)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we should have clean mosaics in which we can identify stars.\n",
    "\n",
    "To identify the stars automatically, we can first smooth by a Gaussian (to approximate the response of the imaging system to a point-like star, and reject noise that doesn't look like a star), then identify the peaks above a threshold.\n",
    "\n",
    "Choose to identify in only one filter, such that those stars are detected in all filters and we don't have to do complicated cross-matching.\n",
    "\n",
    "At the end of this identification step, we want to have in-hand a list of stellar $(x,y)$ positions in the mosaic frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the image with a gaussian\n",
    "%pylab notebook\n",
    "############## This needs to be small to avoid overlaps between stars ########################\n",
    "\n",
    "psf_sig = 3 # [pix]  FIXME  adjust this to an appropriate value commensurate with the width of a star in the image\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "\n",
    "filtered_mosaic = gaussian_filter(mos_V, sigma=psf_sig) # apply the filter\n",
    "\n",
    "# identify peaks in the image\n",
    "from scipy.ndimage import maximum_filter\n",
    "max_filt = int(2.35*psf_sig) # [pix] size of maximum filter\n",
    "mim = maximum_filter(filtered_mosaic, size=max_filt)  # perform maximum filter\n",
    "\n",
    "\n",
    "############################################################################################################\n",
    "\n",
    "#ispeak = ((filtered_mosaic == mim) & (mosaic != 0.)) # value is equal to peak, but isn't zero in original mosaic\n",
    "\n",
    "########## extra constraint for the peaks to avoid non-stars ################################\n",
    "\n",
    "ispeak = ((filtered_mosaic == mim) & (filtered_mosaic != 0.) & (mim >= 10))\n",
    "\n",
    "############## might need to adjust mim ##########################################\n",
    "\n",
    "\n",
    "# now turn these into a list\n",
    "peaklocs = np.nonzero(ispeak) # this is a 2-tuple of 1d arrays\n",
    "starpos_mos_V = np.array(peaklocs).T # this is now an array of N stars by 2\n",
    "N_star_V = starpos_mos_V.shape[0]\n",
    "print(\"{} stars detected\".format(N_star))\n",
    "\n",
    "# show the mosaic and overlay the detections\n",
    "# set up the figure\n",
    "fig = pylab.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "# show the mosaic\n",
    "ax.imshow(mos_V,origin='lower',vmin=0,vmax=100)\n",
    "\n",
    "# annotate the star detections\n",
    "for i in range(N_star_V):\n",
    "    x, y = starpos_mos_V[i,:]\n",
    "    # draw a circle centered at this location\n",
    "    \n",
    "    # write the star number\n",
    "    ax.text(x, y, i,\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center',\n",
    "            )\n",
    "\n",
    "pylab.draw()\n",
    "pylab.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing photometry in each target exposure\n",
    "\n",
    "Now we have a list of stellar positions in the master mosaic frame.\n",
    "\n",
    "We'll want to do the photometry in the individual (calibrated, sky-subtracted) exposures.\n",
    "\n",
    "Not all stars will appear in each exposure.  We will compute the coordinates of all stars in the frame of each exposure (using the frame offsets above), and only get photometry on those stars whose coordinates fall in the field of view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a data structure to hold the photometry.  \n",
    "# For a given filter, each star will have a list of photometric measurements.\n",
    "# Each measurement will correpsond to a (flux, flux_err) tuple\n",
    "# and we'll have a list of all the stars.\n",
    "# So in the end, we'll have a list of lists of 2-tuples.\n",
    "# To start off, we'll have to make a list of length N_star of empty lists.\n",
    "import sys; sys.path.append('/home/a180i/lib/python/')\n",
    "import a180\n",
    "from a180 import ap_pht\n",
    "photometry_V = [[] for i in range(N_star)] # creates a list of empty lists\n",
    "\n",
    "# # now let's loop over all the exposures for this filter\n",
    "# for i, filename in enumerate(reduced_filenames_V):\n",
    "#     # load the calibrated image data\n",
    "\n",
    "#     # get the offset of this frame\n",
    "#     frame_offset = frame_offsets_V[i,:]\n",
    "    \n",
    "for j in range(N_star):\n",
    "        # compute positions of star in this frame\n",
    "    starpos = starpos_mos[j,:]  FIXME  # use starpos_mos and frame_offset\n",
    "\n",
    "        # select stars which fall in this exposure\n",
    "        # use im_shape to find which ones fall in frame\n",
    "    if FIXME:\n",
    "        continue # breaks out of for loop and moves on to next one\n",
    "            \n",
    "        # get aperture photometry for this star\n",
    "    flux, flux_err = \n",
    "        \n",
    "        # perform any sanity checks or calibrations (divide by exposure time?)\n",
    "        \n",
    "        \n",
    "        # store in our data structure\n",
    "    photometry_V[j].append((flux, flux_err))\n",
    "\n",
    "        \n",
    "# now repeat for other filters\n",
    "# perhaps turn above process into a function, which is then fed the list of filenames and frame offsets and exposure times as arguments?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining photometry\n",
    "\n",
    "Now we have, for each filter, a list of photometric measurements (fluxes and estimated errors) for every star.  We want to combine these measurments so that there is a single quantity (flux and error) for each star in each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flux_V, flux_V_err = [], []\n",
    "for flux_meas in photometry_V: # loop over each star's photometry\n",
    "    # turn into an array\n",
    "    flux_meas = np.array(flux_meas)\n",
    "    fluxs = flux_meas[:,0] # all the fluxes\n",
    "    flux_errs = flux_meas[:,1] # all the errors\n",
    "    \n",
    "    # combine\n",
    "    flux = FIXME\n",
    "    flux_err = FIXME\n",
    "    \n",
    "    # store in output\n",
    "    flux_V.append(flux)\n",
    "    flux_V_err.append(flux_err)\n",
    "flux_V = np.array(flux_V)\n",
    "flux_V_err= np.array(flux_V_err)\n",
    "\n",
    "# also do this for other filter.\n",
    "# perhaps re-write above as a function that is passed the photometry in a given band?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photometric calibration\n",
    "\n",
    "We need to use the photometric standard star observations to calibrate the photometry into magnitudes, with associated error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color-Magnitude Diagram\n",
    "\n",
    "Now that we have the photometry for each star in magnitudes (with errors), we can compute the color magnitude diagram, with errorbars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# use errorbar function to make scatter plot with errors in both dimensions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
